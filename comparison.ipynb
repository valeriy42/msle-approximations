{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boiler Plate\n",
    "\n",
    "Following the schema at https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from typing import Tuple\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msle(predt: np.ndarray, dtrain: xgb.DMatrix) -> Tuple[str, float]:\n",
    "    ''' Mean squared log error metric.'''\n",
    "    y = dtrain.get_label()\n",
    "    predt[predt < -1] = -1 + 1e-6\n",
    "    elements = np.power(np.log1p(y) - np.log1p(predt), 2)\n",
    "    return 'MSLE', float(np.mean(elements))\n",
    "\n",
    "def gradient_exact(predt: np.ndarray, dtrain: xgb.DMatrix) -> np.ndarray:\n",
    "    '''Compute the gradient squared log error.'''\n",
    "    y = dtrain.get_label()\n",
    "    return (np.log1p(predt) - np.log1p(y)) / (predt + 1)\n",
    "\n",
    "\n",
    "def evaluate(gradient, hessian):\n",
    "    \n",
    "    iteration = 0\n",
    "    def squared_log(predt: np.ndarray,\n",
    "                    dtrain: xgb.DMatrix) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        '''Squared Log Error objective. A simplified version for RMSLE used as\n",
    "        objective function.\n",
    "        '''\n",
    "        predt[predt < -1] = -1 + 1e-6\n",
    "        grad = gradient(predt, dtrain)\n",
    "        hess = hessian(predt, dtrain)\n",
    "        return grad, hess\n",
    "    \n",
    "    results = {}\n",
    "\n",
    "    xgb.train({'tree_method': 'hist', 'seed': 1994,\n",
    "               'disable_default_eval_metric': 1, 'eta': 0.3},\n",
    "              dtrain=dtrain,\n",
    "              num_boost_round=20,\n",
    "              obj=squared_log,\n",
    "              feval=msle,\n",
    "              evals=[(dtrain, 'dtrain'), (dtest, 'dtest')],\n",
    "              evals_result=results)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('data/housesalesprediction/kc_house_data.csv')\n",
    "\n",
    "y = np.array(X['price'])\n",
    "\n",
    "X.drop(columns=['id', 'date', 'price', 'zipcode', 'lat', 'long', 'sqft_living15',\n",
    "       'sqft_lot15'], inplace=True) # the last once just to keep training faster\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximation using Taylor expension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessian_taylor(predt: np.ndarray, dtrain: xgb.DMatrix) -> np.ndarray:\n",
    "    '''Compute the hessian for squared log error.'''\n",
    "    y = dtrain.get_label()\n",
    "    return ((-np.log1p(predt) + np.log1p(y) + 1) /\n",
    "            np.power(predt + 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tdtrain-MSLE:153.897\tdtest-MSLE:154.235\n",
      "[1]\tdtrain-MSLE:147.884\tdtest-MSLE:148.216\n",
      "[2]\tdtrain-MSLE:141.999\tdtest-MSLE:142.324\n",
      "[3]\tdtrain-MSLE:136.242\tdtest-MSLE:136.561\n",
      "[4]\tdtrain-MSLE:130.612\tdtest-MSLE:130.925\n",
      "[5]\tdtrain-MSLE:125.11\tdtest-MSLE:125.416\n",
      "[6]\tdtrain-MSLE:119.735\tdtest-MSLE:120.034\n",
      "[7]\tdtrain-MSLE:114.487\tdtest-MSLE:114.78\n",
      "[8]\tdtrain-MSLE:109.367\tdtest-MSLE:109.654\n",
      "[9]\tdtrain-MSLE:104.374\tdtest-MSLE:104.655\n",
      "[10]\tdtrain-MSLE:99.5102\tdtest-MSLE:99.7841\n",
      "[11]\tdtrain-MSLE:94.7755\tdtest-MSLE:95.043\n",
      "[12]\tdtrain-MSLE:90.1723\tdtest-MSLE:90.4335\n",
      "[13]\tdtrain-MSLE:85.7039\tdtest-MSLE:85.9588\n",
      "[14]\tdtrain-MSLE:81.3757\tdtest-MSLE:81.6242\n",
      "[15]\tdtrain-MSLE:77.196\tdtest-MSLE:77.4384\n",
      "[16]\tdtrain-MSLE:73.1778\tdtest-MSLE:73.414\n",
      "[17]\tdtrain-MSLE:69.3401\tdtest-MSLE:69.5702\n",
      "[18]\tdtrain-MSLE:65.7091\tdtest-MSLE:65.9333\n",
      "[19]\tdtrain-MSLE:62.3182\tdtest-MSLE:62.5369\n"
     ]
    }
   ],
   "source": [
    "taylor = evaluate(gradient_exact, hessian_taylor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadratic Apprixmation 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessian_approx1(predt: np.ndarray, dtrain: xgb.DMatrix) -> np.ndarray:\n",
    "    '''Compute the hessian for squared log error.'''\n",
    "    y = dtrain.get_label()\n",
    "    return ((np.log1p(predt) - np.log1p(y)) /\n",
    "            ((predt+1)*(predt-y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tdtrain-MSLE:7.35528\tdtest-MSLE:7.4356\n",
      "[1]\tdtrain-MSLE:7.35521\tdtest-MSLE:7.43553\n",
      "[2]\tdtrain-MSLE:7.35514\tdtest-MSLE:7.43546\n",
      "[3]\tdtrain-MSLE:7.35507\tdtest-MSLE:7.43539\n",
      "[4]\tdtrain-MSLE:7.355\tdtest-MSLE:7.43532\n",
      "[5]\tdtrain-MSLE:7.35493\tdtest-MSLE:7.43525\n",
      "[6]\tdtrain-MSLE:7.35486\tdtest-MSLE:7.43518\n",
      "[7]\tdtrain-MSLE:7.35479\tdtest-MSLE:7.43511\n",
      "[8]\tdtrain-MSLE:7.35472\tdtest-MSLE:7.43504\n",
      "[9]\tdtrain-MSLE:7.35465\tdtest-MSLE:7.43497\n",
      "[10]\tdtrain-MSLE:7.35458\tdtest-MSLE:7.4349\n",
      "[11]\tdtrain-MSLE:7.35451\tdtest-MSLE:7.43483\n",
      "[12]\tdtrain-MSLE:7.35444\tdtest-MSLE:7.43476\n",
      "[13]\tdtrain-MSLE:7.35437\tdtest-MSLE:7.43469\n",
      "[14]\tdtrain-MSLE:7.3543\tdtest-MSLE:7.43462\n",
      "[15]\tdtrain-MSLE:7.35423\tdtest-MSLE:7.43454\n",
      "[16]\tdtrain-MSLE:7.35416\tdtest-MSLE:7.43447\n",
      "[17]\tdtrain-MSLE:7.35409\tdtest-MSLE:7.43441\n",
      "[18]\tdtrain-MSLE:7.35402\tdtest-MSLE:7.43434\n",
      "[19]\tdtrain-MSLE:7.35395\tdtest-MSLE:7.43426\n"
     ]
    }
   ],
   "source": [
    "approx1 = evaluate(gradient_exact, hessian_approx1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quadratic Apprixmationm 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_approx2(predt: np.ndarray, dtrain: xgb.DMatrix) -> np.ndarray:\n",
    "    y = dtrain.get_label()\n",
    "    return np.square(np.log1p(predt) - np.log1p(y)) / (predt -y)\n",
    "\n",
    "def hessian_approx2(predt: np.ndarray, dtrain: xgb.DMatrix) -> np.ndarray:\n",
    "    '''Compute the hessian for squared log error.'''\n",
    "    y = dtrain.get_label()\n",
    "    return (np.power(np.log1p(predt) - np.log1p(y), 2)/\n",
    "            np.power(predt - y, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tdtrain-MSLE:139.605\tdtest-MSLE:139.927\n",
      "[1]\tdtrain-MSLE:130.307\tdtest-MSLE:130.619\n",
      "[2]\tdtrain-MSLE:124.262\tdtest-MSLE:124.567\n",
      "[3]\tdtrain-MSLE:119.8\tdtest-MSLE:120.099\n",
      "[4]\tdtrain-MSLE:116.275\tdtest-MSLE:116.57\n",
      "[5]\tdtrain-MSLE:113.369\tdtest-MSLE:113.661\n",
      "[6]\tdtrain-MSLE:110.902\tdtest-MSLE:111.191\n",
      "[7]\tdtrain-MSLE:108.762\tdtest-MSLE:109.048\n",
      "[8]\tdtrain-MSLE:106.876\tdtest-MSLE:107.159\n",
      "[9]\tdtrain-MSLE:105.19\tdtest-MSLE:105.471\n",
      "[10]\tdtrain-MSLE:103.668\tdtest-MSLE:103.947\n",
      "[11]\tdtrain-MSLE:102.281\tdtest-MSLE:102.559\n",
      "[12]\tdtrain-MSLE:101.009\tdtest-MSLE:101.285\n",
      "[13]\tdtrain-MSLE:99.8349\tdtest-MSLE:100.109\n",
      "[14]\tdtrain-MSLE:98.7447\tdtest-MSLE:99.0176\n",
      "[15]\tdtrain-MSLE:97.7278\tdtest-MSLE:97.9994\n",
      "[16]\tdtrain-MSLE:96.7755\tdtest-MSLE:97.0457\n",
      "[17]\tdtrain-MSLE:95.8802\tdtest-MSLE:96.1493\n",
      "[18]\tdtrain-MSLE:95.0359\tdtest-MSLE:95.3038\n",
      "[19]\tdtrain-MSLE:94.2372\tdtest-MSLE:94.504\n"
     ]
    }
   ],
   "source": [
    "approx2 = evaluate(gradient_approx2, hessian_approx2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
